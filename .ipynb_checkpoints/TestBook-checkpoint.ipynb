{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "#import extract_scalars as es\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"summaries_test/\"\n",
    "summaryFiles = os.listdir(folder)\n",
    "output_dir = \"csv_output\"\n",
    "\n",
    "if output_dir not in os.listdir(folder):\n",
    "    os.mkdir(folder+output_dir)\n",
    "\n",
    "tag_names = {\"Environment/Cumulative Reward\":1,\"Environment/Episode Length\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryFiles = [file for file in summaryFiles if ((\"csv\") or (\"py\")) not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structureFiles(files):\n",
    "    # Separating the run-id and run-num from the brain tag.\n",
    "    fileNames = [re.split(\"_\",file) for file in files]\n",
    "    \n",
    "    # Continuing with run-id and run-num\n",
    "    cleanedFileNames = [file[0] for file in fileNames]\n",
    "    \n",
    "    # Storing brain tag for later use\n",
    "    ending = fileNames[0][1:]\n",
    "    ending = \"_\" + ending[0] + \"_\" + ending[1]\n",
    "\n",
    "    # Creating a splitted list for each of the cleaned file name, for later comparison\n",
    "    splittedCleanedName = [re.split(\"[-.]\",file) for file in cleanedFileNames]\n",
    "    \n",
    "    # Structing the different datasets (event files from tensorflow).\n",
    "    similar = []\n",
    "    for i,name in enumerate(cleanedFileNames):\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            similar.append([name])\n",
    "\n",
    "        else:\n",
    "\n",
    "            if len(splittedCleanedName[i]) == len(splittedCleanedName[i-1]):\n",
    "\n",
    "                whereSimilar = [splittedCleanedName[i][j]==splittedCleanedName[i-1][j] for j in \\\n",
    "                                                                 np.arange(len(splittedCleanedName[i]))]\n",
    "\n",
    "                pos = [l for l,ele in enumerate(whereSimilar) if ele == 0][0]\n",
    "\n",
    "                if pos == (len(splittedCleanedName[i]) - 1):\n",
    "\n",
    "                    similar[len(similar) - 1].append(name)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    similar.append([name])\n",
    "\n",
    "            else:\n",
    "\n",
    "                similar.append([name])\n",
    "    \n",
    "    # returning the structured data.\n",
    "    return similar,ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventToCSV(folder,file,tags,end):\n",
    "    \n",
    "    # Getting the event file\n",
    "    eventfile = os.listdir(folder+file+end)\n",
    "    filePath = folder+file+end+\"/\"+eventfile[0]\n",
    "    \n",
    "    # Store the data.\n",
    "    data = [[] for tag in np.arange(len(list(tags.keys()))+1)]\n",
    "    \n",
    "    # Extracting the data.\n",
    "    for event in tf.train.summary_iterator(filePath):\n",
    "        \n",
    "        # Storing the step.\n",
    "        data[0].append(event.step)\n",
    "        \n",
    "        # Storing the values of interest.\n",
    "        for value in event.summary.value:\n",
    "\n",
    "            if value.tag in list(tags.keys()):\n",
    "\n",
    "                data[tag_names[value.tag]].append(value.simple_value)\n",
    "        \n",
    "    data[0] = data[0][2:]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "structuredFiles, ending = structureFiles(summaryFiles)\n",
    "\n",
    "# Preparing to write out the csv file.\n",
    "header = [\"Step\"]\n",
    "\n",
    "for tag in list(tag_names.keys()):\n",
    "    # Removing the overall tag, which is the first in the tag_name and continuing with the actual\n",
    "    # tag name.\n",
    "    header.append(re.sub(\" \",\"_\",re.split(\"/\",tag)[1]))\n",
    "\n",
    "for fileGroup in structuredFiles:\n",
    "\n",
    "    if len(fileGroup) == 1:\n",
    "        frame = pd.DataFrame(eventToCSV(folder,fileGroup[0],tag_names,ending))#,columns = header\n",
    "        frame = frame.rename(columns=frame.iloc[0]).drop(frame.index[0])\n",
    "        frame.to_csv(output_dir+\"/\"+fileGroup[0]+\".csv\")\n",
    "        \n",
    "    else:\n",
    "\n",
    "        for i,f in enumerate(fileGroup):\n",
    "            tracker = np.arange(len(fileGroup)+len(tag_names)+1)\n",
    "            \n",
    "            if i == 0:\n",
    "                \n",
    "                frame = pd.DataFrame(eventToCSV(folder,f,tag_names,ending))\n",
    "            else:\n",
    "\n",
    "                frame_1 = pd.DataFrame(eventToCSV(folder,f,tag_names,ending))\n",
    "                frame = pd.concat([frame,frame_1.loc[1:2]],ignore_index=True)\n",
    "\n",
    "        frame = frame.rename(columns=frame.iloc[0]).drop(frame.index[0])\n",
    "        frame.to_csv(output_dir+\"/\"+fileGroup[0]+\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = [re.split(\"_\",file) for file in summaryFiles]\n",
    "cleanedFileNames = [file[0] for file in fileNames]\n",
    "ending = fileNames[0][1:]\n",
    "ending = \"_\" + ending[0] + \"_\" + ending[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_GoalBrain_4'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benchmarking-1.0-0',\n",
       " 'Benchmarking-1.1-0',\n",
       " 'Benchmarking-1.2-0',\n",
       " 'Benchmarking-2.1-0',\n",
       " 'Benchmarking-2.2-0',\n",
       " 'Benchmarking-2.3-0',\n",
       " 'Benchmarking-2.4-0',\n",
       " 'Benchmarking-2.5-0',\n",
       " 'Benchmarking-2.6-0',\n",
       " 'Benchmarking-3.1-0',\n",
       " 'Benchmarking-3.2-0',\n",
       " 'Benchmarking-4.1-0',\n",
       " 'Benchmarking-4.2-0',\n",
       " 'Benchmarking-4.3-0',\n",
       " 'Candidate-1.0-0',\n",
       " 'Candidate-1.0-1',\n",
       " 'Candidate-1.0-2',\n",
       " 'Candidate-1.0.1-0',\n",
       " 'Candidate-1.0.1-1',\n",
       " 'Candidate-1.0.1-2',\n",
       " 'Candidate-1.1-0',\n",
       " 'Candidate-1.1-1',\n",
       " 'Candidate-1.1-2',\n",
       " 'Candidate-1.2-0',\n",
       " 'Candidate-1.2-1',\n",
       " 'Candidate-1.2-2',\n",
       " 'Candidate-1.3-0',\n",
       " 'Candidate-1.3-1',\n",
       " 'Candidate-1.3-2',\n",
       " 'Candidate-1.4-0',\n",
       " 'Candidate-1.4-1',\n",
       " 'Candidate-1.4-2',\n",
       " 'Pedestrians-1.0-0',\n",
       " 'Pedestrians-1.0-1',\n",
       " 'Pedestrians-1.0-2',\n",
       " 'Pedestrians-1.0.1-0',\n",
       " 'Pedestrians-1.0.1-1',\n",
       " 'Pedestrians-1.0.1-2',\n",
       " 'Pedestrians-1.2-0',\n",
       " 'Pedestrians-1.2-1',\n",
       " 'Pedestrians-1.2-2',\n",
       " 'Pedestrians-1.3-0',\n",
       " 'Pedestrians-1.3-1',\n",
       " 'Pedestrians-1.3-2',\n",
       " 'SensorClouds-1.0-0',\n",
       " 'SensorClouds-1.0-1',\n",
       " 'SensorClouds-1.0-2',\n",
       " 'SensorClouds-1.2-0',\n",
       " 'SensorClouds-1.2-1',\n",
       " 'SensorClouds-1.2-2',\n",
       " 'SensorClouds-1.3-0',\n",
       " 'SensorClouds-1.3-1',\n",
       " 'SensorClouds-1.3-2']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedFileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "splittedCleanedName = [re.split(\"[-.]\",file) for file in cleanedFileNames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = []\n",
    "for i,name in enumerate(cleanedFileNames):\n",
    "    \n",
    "    if i == 0:\n",
    "        \n",
    "        similar.append([name])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if len(splittedCleanedName[i]) == len(splittedCleanedName[i-1]):\n",
    "            \n",
    "            whereSimilar = [splittedCleanedName[i][j]==splittedCleanedName[i-1][j] for j in \\\n",
    "                                                             np.arange(len(splittedCleanedName[i]))]\n",
    "            \n",
    "            pos = [l for l,ele in enumerate(whereSimilar) if ele == 0][0]\n",
    "            \n",
    "            if pos == (len(splittedCleanedName[i]) - 1):\n",
    "                \n",
    "                similar[len(similar) - 1].append(name)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                similar.append([name])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            similar.append([name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Benchmarking-1.0-0'],\n",
       " ['Benchmarking-1.1-0'],\n",
       " ['Benchmarking-1.2-0'],\n",
       " ['Benchmarking-2.1-0'],\n",
       " ['Benchmarking-2.2-0'],\n",
       " ['Benchmarking-2.3-0'],\n",
       " ['Benchmarking-2.4-0'],\n",
       " ['Benchmarking-2.5-0'],\n",
       " ['Benchmarking-2.6-0'],\n",
       " ['Benchmarking-3.1-0'],\n",
       " ['Benchmarking-3.2-0'],\n",
       " ['Benchmarking-4.1-0'],\n",
       " ['Benchmarking-4.2-0'],\n",
       " ['Benchmarking-4.3-0'],\n",
       " ['Candidate-1.0-0', 'Candidate-1.0-1', 'Candidate-1.0-2'],\n",
       " ['Candidate-1.0.1-0', 'Candidate-1.0.1-1', 'Candidate-1.0.1-2'],\n",
       " ['Candidate-1.1-0', 'Candidate-1.1-1', 'Candidate-1.1-2'],\n",
       " ['Candidate-1.2-0', 'Candidate-1.2-1', 'Candidate-1.2-2'],\n",
       " ['Candidate-1.3-0', 'Candidate-1.3-1', 'Candidate-1.3-2'],\n",
       " ['Candidate-1.4-0', 'Candidate-1.4-1', 'Candidate-1.4-2'],\n",
       " ['Pedestrians-1.0-0', 'Pedestrians-1.0-1', 'Pedestrians-1.0-2'],\n",
       " ['Pedestrians-1.0.1-0', 'Pedestrians-1.0.1-1', 'Pedestrians-1.0.1-2'],\n",
       " ['Pedestrians-1.2-0', 'Pedestrians-1.2-1', 'Pedestrians-1.2-2'],\n",
       " ['Pedestrians-1.3-0', 'Pedestrians-1.3-1', 'Pedestrians-1.3-2'],\n",
       " ['SensorClouds-1.0-0', 'SensorClouds-1.0-1', 'SensorClouds-1.0-2'],\n",
       " ['SensorClouds-1.2-0', 'SensorClouds-1.2-1', 'SensorClouds-1.2-2'],\n",
       " ['SensorClouds-1.3-0', 'SensorClouds-1.3-1', 'SensorClouds-1.3-2']]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 27), match='BaseEnvironmentNoCurriculum'>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search('(?<![0-9])\\w+',summaryFiles[0])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaseEnvironmentNoCurriculum-0', 'GoalBrain', '4']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"_\",summaryFiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_names = {\"Environment/Cumulative Reward\":1,\"Environment/Episode Length\":2}#Environment_Cumulative Reward\",\"Environment_Episode Length\", \"Policy/Value Estimate\" \n",
    "# run_names=summaryFiles[:]\n",
    "#run_names = [\"hej\"]#summaryFiles[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in summaryFiles:\n",
    "    \n",
    "    eventfile = os.listdir(folder+file)\n",
    "    filePath = folder+file+\"/\"+eventfile[0]\n",
    "    # Store the data.\n",
    "    data = [[] for tag in np.arange(len(list(tag_names.keys()))+1)]\n",
    "    \n",
    "    # Extracting the data.\n",
    "    for event in tf.train.summary_iterator(filePath):\n",
    "        \n",
    "        # Storing the step.\n",
    "        data[0].append(event.step)\n",
    "        \n",
    "        # Storing the values of interest.\n",
    "        for value in event.summary.value:\n",
    "\n",
    "            if value.tag in list(tag_names.keys()):\n",
    "\n",
    "                data[tag_names[value.tag]].append(value.simple_value)\n",
    "        \n",
    "    data[0] = data[0][2:]\n",
    "    # Preparing to write out the csv file.\n",
    "    header = [\"Step\"]\n",
    "    \n",
    "    for tag in list(tag_names.keys()):\n",
    "        # Removing the overall tag, which is the first in the tag_name and continuing with the actual\n",
    "        # tag name.\n",
    "        header.append(re.sub(\" \",\"_\",re.split(\"/\",tag)[1]))\n",
    "    \n",
    "    with open(\"csv_output/\"+file+\".csv\", \"w\") as outputfile:\n",
    "        writer = csv.writer(outputfile)\n",
    "        # Adding the header\n",
    "        writer.writerow(header)\n",
    "        # Adding the observations\n",
    "        for obs in np.arange(len(data[0])):\n",
    "            writer.writerow([newEle[obs] for newEle in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for ls in data:\n",
    "    print(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000,\n",
       " 2000,\n",
       " 3000,\n",
       " 4000,\n",
       " 5000,\n",
       " 6000,\n",
       " 7000,\n",
       " 8000,\n",
       " 9000,\n",
       " 10000,\n",
       " 11000,\n",
       " 12000,\n",
       " 13000,\n",
       " 14000,\n",
       " 15000,\n",
       " 16000,\n",
       " 17000,\n",
       " 18000,\n",
       " 19000,\n",
       " 20000,\n",
       " 21000,\n",
       " 22000,\n",
       " 23000,\n",
       " 24000,\n",
       " 25000,\n",
       " 26000,\n",
       " 27000,\n",
       " 28000,\n",
       " 29000,\n",
       " 30000,\n",
       " 31000,\n",
       " 32000,\n",
       " 33000,\n",
       " 34000,\n",
       " 35000,\n",
       " 36000,\n",
       " 37000,\n",
       " 38000,\n",
       " 39000,\n",
       " 40000,\n",
       " 41000,\n",
       " 42000,\n",
       " 43000,\n",
       " 44000,\n",
       " 45000,\n",
       " 46000,\n",
       " 47000,\n",
       " 48000,\n",
       " 49000,\n",
       " 50000,\n",
       " 51000,\n",
       " 52000,\n",
       " 53000,\n",
       " 54000,\n",
       " 55000,\n",
       " 56000,\n",
       " 57000,\n",
       " 58000,\n",
       " 59000,\n",
       " 60000,\n",
       " 61000,\n",
       " 62000,\n",
       " 63000,\n",
       " 64000,\n",
       " 65000,\n",
       " 66000,\n",
       " 67000,\n",
       " 68000,\n",
       " 69000,\n",
       " 70000,\n",
       " 71000,\n",
       " 72000,\n",
       " 73000,\n",
       " 74000,\n",
       " 75000,\n",
       " 76000,\n",
       " 77000,\n",
       " 78000,\n",
       " 79000,\n",
       " 80000,\n",
       " 81000,\n",
       " 82000,\n",
       " 83000,\n",
       " 84000,\n",
       " 85000,\n",
       " 86000,\n",
       " 87000,\n",
       " 88000,\n",
       " 89000,\n",
       " 90000,\n",
       " 91000,\n",
       " 92000,\n",
       " 93000,\n",
       " 94000,\n",
       " 95000,\n",
       " 96000,\n",
       " 97000,\n",
       " 98000,\n",
       " 99000,\n",
       " 100000,\n",
       " 101000,\n",
       " 102000,\n",
       " 103000,\n",
       " 104000,\n",
       " 105000,\n",
       " 106000,\n",
       " 107000,\n",
       " 108000,\n",
       " 109000,\n",
       " 110000,\n",
       " 111000,\n",
       " 112000,\n",
       " 113000,\n",
       " 114000,\n",
       " 115000,\n",
       " 116000,\n",
       " 117000,\n",
       " 118000,\n",
       " 119000,\n",
       " 120000,\n",
       " 121000,\n",
       " 122000,\n",
       " 123000,\n",
       " 124000,\n",
       " 125000,\n",
       " 126000,\n",
       " 127000,\n",
       " 128000,\n",
       " 129000,\n",
       " 130000,\n",
       " 131000,\n",
       " 132000,\n",
       " 133000,\n",
       " 134000,\n",
       " 135000,\n",
       " 136000,\n",
       " 137000,\n",
       " 138000,\n",
       " 139000,\n",
       " 140000,\n",
       " 141000,\n",
       " 142000,\n",
       " 143000,\n",
       " 144000,\n",
       " 145000,\n",
       " 146000,\n",
       " 147000,\n",
       " 148000,\n",
       " 149000,\n",
       " 150000,\n",
       " 151000,\n",
       " 152000,\n",
       " 153000,\n",
       " 154000,\n",
       " 155000,\n",
       " 156000,\n",
       " 157000,\n",
       " 158000,\n",
       " 159000,\n",
       " 160000,\n",
       " 161000,\n",
       " 162000,\n",
       " 163000,\n",
       " 164000,\n",
       " 165000,\n",
       " 166000,\n",
       " 167000,\n",
       " 168000,\n",
       " 169000,\n",
       " 170000,\n",
       " 171000,\n",
       " 172000,\n",
       " 173000,\n",
       " 174000,\n",
       " 175000,\n",
       " 176000,\n",
       " 177000,\n",
       " 178000,\n",
       " 179000,\n",
       " 180000,\n",
       " 181000,\n",
       " 182000,\n",
       " 183000,\n",
       " 184000,\n",
       " 185000,\n",
       " 186000,\n",
       " 187000,\n",
       " 188000,\n",
       " 189000,\n",
       " 190000,\n",
       " 191000,\n",
       " 192000,\n",
       " 193000,\n",
       " 194000,\n",
       " 195000,\n",
       " 196000,\n",
       " 197000,\n",
       " 198000,\n",
       " 199000,\n",
       " 200000]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data\n",
    "data = [[] for tag in tag_names.keys()]\n",
    "\n",
    "for event in tf.train.summary_iterator(\"test_summaries/\"+summaryFiles[0]+\"/\"+file[0]):\n",
    "    for value in event.summary.value:\n",
    "        if value.tag in list(tag_names.keys()):\n",
    "            data[tag_names[value.tag]].append(value.simple_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.0316437482833862,\n",
       "  -1.036031723022461,\n",
       "  -1.0053520202636719,\n",
       "  -0.9727733731269836,\n",
       "  -1.0429385900497437,\n",
       "  -1.0042332410812378,\n",
       "  -1.0384016036987305,\n",
       "  -1.0052272081375122,\n",
       "  -1.0414034128189087,\n",
       "  -1.0069999694824219,\n",
       "  -1.0417982339859009,\n",
       "  -0.9680287837982178,\n",
       "  -1.0500520467758179,\n",
       "  -0.9557926058769226,\n",
       "  -1.0410887002944946,\n",
       "  -1.048112154006958,\n",
       "  -1.050265908241272,\n",
       "  -1.053833246231079,\n",
       "  -1.0392372608184814,\n",
       "  -0.9494117498397827,\n",
       "  -1.0384835004806519,\n",
       "  -1.0294885635375977,\n",
       "  -0.9573610424995422,\n",
       "  -1.012647032737732,\n",
       "  -1.0160714387893677,\n",
       "  -0.9003471732139587,\n",
       "  -1.0650675296783447,\n",
       "  -0.8986110687255859,\n",
       "  -1.1235713958740234,\n",
       "  -0.9617072343826294,\n",
       "  -1.0636110305786133,\n",
       "  -1.0164165496826172,\n",
       "  -1.018899917602539,\n",
       "  -1.0234209299087524,\n",
       "  -1.1097726821899414,\n",
       "  -0.944568932056427,\n",
       "  -1.0196999311447144,\n",
       "  -1.1048911809921265,\n",
       "  -1.0185576677322388,\n",
       "  -1.0871295928955078,\n",
       "  -1.0967307090759277,\n",
       "  -1.0171998739242554,\n",
       "  -1.0167391300201416,\n",
       "  -0.9331249594688416,\n",
       "  -1.1597726345062256,\n",
       "  -0.8846590518951416,\n",
       "  -1.0165475606918335,\n",
       "  -1.1097825765609741,\n",
       "  -0.9405555129051208,\n",
       "  -0.9095587730407715,\n",
       "  -1.1108332872390747,\n",
       "  -1.022045373916626,\n",
       "  -1.1124999523162842,\n",
       "  -1.1066303253173828,\n",
       "  -0.775882363319397,\n",
       "  -1.0347367525100708,\n",
       "  -1.131710410118103,\n",
       "  -0.7728124856948853,\n",
       "  -0.9173684120178223,\n",
       "  -1.0183695554733276,\n",
       "  -1.0226315259933472,\n",
       "  -0.9139062166213989,\n",
       "  -1.026911735534668,\n",
       "  -1.1255263090133667,\n",
       "  -0.7980555295944214,\n",
       "  -0.9152940511703491,\n",
       "  -1.0411537885665894,\n",
       "  -0.5603845715522766,\n",
       "  -0.8885714411735535,\n",
       "  -0.7353571057319641,\n",
       "  -0.7868332862854004,\n",
       "  -0.8706249594688416,\n",
       "  -0.8805768489837646,\n",
       "  -0.7029166221618652,\n",
       "  -0.7822222113609314,\n",
       "  -0.7866666316986084,\n",
       "  -0.23074999451637268,\n",
       "  -0.5164999961853027,\n",
       "  -0.5608823299407959,\n",
       "  -0.528333306312561,\n",
       "  -0.861136257648468,\n",
       "  -0.7118749618530273,\n",
       "  -0.33791670203208923,\n",
       "  -0.39083331823349,\n",
       "  -0.7960293889045715,\n",
       "  -0.8227499723434448,\n",
       "  -0.4350000023841858,\n",
       "  -0.31333327293395996,\n",
       "  -0.5618181824684143,\n",
       "  -0.5337499976158142,\n",
       "  -0.6949999928474426,\n",
       "  -1.2073214054107666,\n",
       "  -0.7999999523162842,\n",
       "  -0.23133333027362823,\n",
       "  -0.3735416829586029,\n",
       "  -0.7959374785423279,\n",
       "  -0.793571412563324,\n",
       "  -0.20416663587093353,\n",
       "  -0.767727255821228,\n",
       "  0.056111060082912445,\n",
       "  -0.7917856574058533,\n",
       "  -0.3577083349227905,\n",
       "  -0.25724998116493225,\n",
       "  -0.4573213756084442,\n",
       "  -0.37361109256744385,\n",
       "  -0.6650000214576721,\n",
       "  -0.2787500321865082,\n",
       "  -0.13346156477928162,\n",
       "  -0.2224999964237213,\n",
       "  0.2566071152687073,\n",
       "  0.04295451194047928,\n",
       "  -0.22600004076957703,\n",
       "  -0.319090873003006,\n",
       "  -0.046607159078121185,\n",
       "  -0.671999990940094,\n",
       "  0.04183332994580269,\n",
       "  -0.5136363506317139,\n",
       "  0.06249998137354851,\n",
       "  0.36194440722465515,\n",
       "  -0.01928575150668621,\n",
       "  -0.14269231259822845,\n",
       "  0.20714282989501953,\n",
       "  -0.037777822464704514,\n",
       "  0.28333330154418945,\n",
       "  -1.045714259147644,\n",
       "  -0.11041668802499771,\n",
       "  0.16124998033046722,\n",
       "  0.08749996870756149,\n",
       "  -0.16555561125278473,\n",
       "  0.05249996855854988,\n",
       "  0.06624995917081833,\n",
       "  0.27687495946884155,\n",
       "  -0.4191666841506958,\n",
       "  -0.05468754097819328,\n",
       "  0.11299993097782135,\n",
       "  0.36464282870292664,\n",
       "  0.46666663885116577,\n",
       "  -0.45357146859169006,\n",
       "  0.5656817555427551,\n",
       "  -0.24000002443790436,\n",
       "  -0.2703571617603302,\n",
       "  0.2178124338388443,\n",
       "  0.4418749213218689,\n",
       "  0.4059090316295624,\n",
       "  0.7536363005638123,\n",
       "  0.21843746304512024,\n",
       "  0.4949999749660492,\n",
       "  0.06349992752075195,\n",
       "  0.5763888359069824,\n",
       "  0.34678563475608826,\n",
       "  -0.37562498450279236,\n",
       "  0.304999977350235,\n",
       "  0.5041666030883789,\n",
       "  0.5838636159896851,\n",
       "  0.21093745529651642,\n",
       "  0.7682141661643982,\n",
       "  -0.17718754708766937,\n",
       "  -0.296875,\n",
       "  0.5813635587692261,\n",
       "  0.5296428203582764,\n",
       "  0.5652499198913574,\n",
       "  0.3059374690055847,\n",
       "  0.305208295583725,\n",
       "  -0.14625006914138794,\n",
       "  0.6937499046325684,\n",
       "  0.1867307424545288,\n",
       "  -0.33638885617256165,\n",
       "  0.450999915599823,\n",
       "  0.2665908634662628,\n",
       "  -0.10458339005708694,\n",
       "  0.034285690635442734,\n",
       "  0.11374993622303009,\n",
       "  0.7308332920074463,\n",
       "  0.21187494695186615,\n",
       "  0.41093742847442627,\n",
       "  -1.7374999523162842,\n",
       "  -0.24125008285045624,\n",
       "  -0.18750005960464478,\n",
       "  0.35774993896484375,\n",
       "  0.04499990493059158,\n",
       "  -0.5075000524520874,\n",
       "  0.29166659712791443,\n",
       "  0.5038888454437256,\n",
       "  0.4368181526660919,\n",
       "  0.03649997338652611,\n",
       "  0.11849995702505112,\n",
       "  0.5712499022483826,\n",
       "  -0.030833374708890915,\n",
       "  0.20124997198581696,\n",
       "  0.4849999248981476,\n",
       "  0.6755554676055908,\n",
       "  0.7222221493721008,\n",
       "  0.4522727131843567,\n",
       "  0.30699995160102844,\n",
       "  -0.6975000500679016,\n",
       "  0.09937494993209839,\n",
       "  0.057045429944992065,\n",
       "  0.0912499725818634,\n",
       "  -0.15250003337860107,\n",
       "  -0.2970000207424164]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "INFO:tensorflow:Event Multiplexer initializing.\n",
      "INFO:tensorflow:Event Multiplexer done initializing\n",
      "INFO:tensorflow:Starting AddRunsFromDirectory: test_summaries/BaseEnvironmentNoCurriculum-0_GoalBrain_4\n",
      "INFO:tensorflow:GetLogdirSubdirectories: Starting to list directories via walking.\n",
      "INFO:tensorflow:Adding run from directory test_summaries/BaseEnvironmentNoCurriculum-0_GoalBrain_4\n",
      "INFO:tensorflow:Constructing EventAccumulator for test_summaries/BaseEnvironmentNoCurriculum-0_GoalBrain_4\n",
      "INFO:tensorflow:Done with AddRunsFromDirectory: test_summaries/BaseEnvironmentNoCurriculum-0_GoalBrain_4\n",
      "INFO:tensorflow:Beginning EventMultiplexer.Reload()\n",
      "INFO:tensorflow:Reloading runs serially (one after another) on the main thread.\n",
      "INFO:tensorflow:No path found after test_summaries/BaseEnvironmentNoCurriculum-0_GoalBrain_4\\events.out.tfevents.1563706320.PC\n",
      "INFO:tensorflow:Finished with EventMultiplexer.Reload()\n",
      "Exporting (run='BaseEnvironmentNoCurriculum-0_GoalBrain_4', tag='Environment/Cumulative Reward') to 'csv_output\\\\BaseEnvironmentNoCurriculum_0_GoalBrain_4___Environment_Cumulative_Reward'...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'BaseEnvironmentNoCurriculum-0_GoalBrain_4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c44798a1ca2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m           \u001b[1;34m\"Exporting (run=%r, tag=%r) to %r...\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m           % (run_name, tag_name, output_filepath))\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_scalars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\GitHub\\Dissertation-UCL\\extract_scalars.py\u001b[0m in \u001b[0;36mexport_scalars\u001b[1;34m(multiplexer, run, tag, filepath, write_headers)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexport_scalars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_headers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_scalars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\GitHub\\Dissertation-UCL\\extract_scalars.py\u001b[0m in \u001b[0;36mextract_scalars\u001b[1;34m(multiplexer, run, tag)\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[0mThe\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtuples\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwall_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \"\"\"\n\u001b[1;32m---> 25\u001b[1;33m   \u001b[0mtensor_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiplexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m   return [\n\u001b[0;32m     27\u001b[0m       \u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwall_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\backend\\event_processing\\plugin_event_multiplexer.py\u001b[0m in \u001b[0;36mTensors\u001b[1;34m(self, run, tag)\u001b[0m\n\u001b[0;32m    395\u001b[0m       \u001b[0mAn\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mevent_accumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorEvent\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \"\"\"\n\u001b[1;32m--> 397\u001b[1;33m     \u001b[0maccumulator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetAccumulator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maccumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorboard\\backend\\event_processing\\plugin_event_multiplexer.py\u001b[0m in \u001b[0;36mGetAccumulator\u001b[1;34m(self, run)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \"\"\"\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulators_mutex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accumulators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'BaseEnvironmentNoCurriculum-0_GoalBrain_4'"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#   run_names = (\n",
    "#       'scalars_demo/temperature:t0=270,tA=270,kH=%s' % x\n",
    "#       for x in ('0.001', '0.005')\n",
    "#   )\n",
    "#   tag_names = ('temperature/current/scalar_summary', 'delta/scalar_summary')\n",
    "\n",
    "logdir = 'test_summaries/'+summaryFiles[0]\n",
    "output_dir = 'csv_output'\n",
    "es.mkdir_p(output_dir)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "multiplexer = es.create_multiplexer(logdir)\n",
    "for run_name in run_names:\n",
    "    for tag_name in tag_names:\n",
    "        output_filename = '%s___%s' % (\n",
    "          es.munge_filename(run_name), es.munge_filename(tag_name))\n",
    "        output_filepath = os.path.join(output_dir, output_filename)\n",
    "        print(\n",
    "          \"Exporting (run=%r, tag=%r) to %r...\"\n",
    "          % (run_name, tag_name, output_filepath))\n",
    "        es.export_scalars(multiplexer, run_name, tag_name, output_filepath)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
